{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing genai library from Google Before you can use the Gemini API, you must first obtain an API key. If you don't already have one, create a key with one click in Google AI Studio.\n",
    "\n",
    "<a class=\"button button-primary\" href=\"https://makersuite.google.com/app/apikey\" target=\"_blank\" rel=\"noopener noreferrer\">Get an API key</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\faree\\Desktop\\gemini_chatbot\\.venv-gemini-bot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "# Your API key goes here\n",
    "genai.configure(api_key=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert string of dict to dict using ast\n",
    "import ast\n",
    "def convert_str_to_dict(dict_str):\n",
    "    dict_str = dict_str.replace(\"True\", \"True,\")\n",
    "    dict_str = dict_str.replace(\"False\", \"False,\")\n",
    "    dict_str = dict_str.replace(\"None\", \"None,\")\n",
    "    return ast.literal_eval(dict_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Classification:**\n",
    "   - Sentiment Analysis\n",
    "   - Topic Classification\n",
    "   - Spam Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Neutral\n",
      "\n",
      "Short explanation:\n",
      "\n",
      "The input text expresses both positive and negative sentiment. The author expresses a love for playing football, which is a positive sentiment. However, the author also expresses sadness and a lack of desire to play football today, which are negative sentiments. Overall, the tone of the input text is neutral, as the positive and negative sentiments balance each other out.\n"
     ]
    }
   ],
   "source": [
    "#################################### Sentiment Analysis ####################################\n",
    "\n",
    "# explanation needed?\n",
    "explanation = 'yes'\n",
    "\n",
    "# category\n",
    "category = '''positive, negative, neutral'''\n",
    "\n",
    "if category != '':\n",
    "    category = '''positive, negative, neutral'''\n",
    "else:\n",
    "    category = category    \n",
    "\n",
    "# input text\n",
    "user_input = \"I love to play football, but today I am feeling very sad. I do not want to play football today.\"\n",
    "\n",
    "# check explanation is required\n",
    "if explanation == 'yes':\n",
    "    explanation = 'short explanation: '\n",
    "else:\n",
    "    explanation = 'no explanation'\n",
    "\n",
    "# question to be asked\n",
    "question = f'''Given the input text, perform sentiment analysis on it\n",
    "cateogry: positive, negative, neutral\n",
    "{user_input}\n",
    "{explanation}\n",
    "'''\n",
    "\n",
    "# generate response\n",
    "response = model.generate_content(question)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: Story\n",
      "\n",
      "Explanation: The text is a short story about someone who loves to play football but is feeling sad and does not want to play today. It is not a horror story or a comedy, so the other topics are not appropriate.\n"
     ]
    }
   ],
   "source": [
    "#################################### Topic Classification ####################################\n",
    "\n",
    "# explanation needed?\n",
    "explanation = 'yes'\n",
    "\n",
    "# category\n",
    "topics = '''topics are: story, horror, comedy'''\n",
    "\n",
    "# input text\n",
    "user_input = \"I love to play football, but today I am feeling very sad. I do not want to play football today.\"\n",
    "\n",
    "# check explanation is required\n",
    "if explanation == 'yes':\n",
    "    explanation = 'short explanation: '\n",
    "else:\n",
    "    explanation = 'no explanation'\n",
    "\n",
    "# question to be asked\n",
    "question = f'''Given the input text, perform Topic Classification on it\n",
    "{topics}\n",
    "{user_input}\n",
    "{explanation}\n",
    "'''\n",
    "\n",
    "# generate response\n",
    "response = model.generate_content(question)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "#################################### Spam Detection ####################################\n",
    "\n",
    "# explanation needed?\n",
    "explanation = 'yes'\n",
    "\n",
    "# category\n",
    "cateogry = '''spam, not_spam, unkown'''\n",
    "\n",
    "# input text\n",
    "user_input = \"you have just won 14000$ dollars ticker claim this award here at this link.\"\n",
    "\n",
    "# check explanation is required\n",
    "if explanation == 'yes':\n",
    "    explanation = 'provide short explanation'\n",
    "else:\n",
    "    explanation = 'no explanation'\n",
    "\n",
    "# question to be asked\n",
    "question = f'''Given the input text, perform spam detect on it\n",
    "{cateogry}\n",
    "{user_input}\n",
    "{explanation}\n",
    "'''\n",
    "\n",
    "# generate response\n",
    "response = model.generate_content(question)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Named Entity Recognition (NER):**\n",
    "   - Identifying entities (e.g., persons, organizations, locations etc) in text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airport: facility\n",
      "12:00 AM: time\n"
     ]
    }
   ],
   "source": [
    "#################################### NER Detection ####################################\n",
    "\n",
    "# category\n",
    "ner_tags = '''person, location, date, number, organization, time, money, percent, facility, product, event, language, law, ordinal, misc, quantity, cardinal'''\n",
    "\n",
    "# input text\n",
    "user_input = \"I will meet you at airport sharp 12:00 AM.\"\n",
    "\n",
    "# question to be asked\n",
    "question = f'''Given the input text, perform NER detection on it\n",
    "NER Tags are: {ner_tags}\n",
    "{user_input}\n",
    "answer must be in format\n",
    "word: entity\n",
    "'''\n",
    "\n",
    "# generate response\n",
    "response = model.generate_content(question)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part-of-Speech Tagging (POS):**\n",
    "   - Assigning grammatical categories (e.g., noun, verb, adjective) to words in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: pronoun\n",
      "will: verb\n",
      "meet: verb\n",
      "you: pronoun\n",
      "at: preposition\n",
      "airport: noun\n",
      "sharp: adjective\n",
      "12:00: time\n",
      "AM: time\n",
      ".: punctuation\n"
     ]
    }
   ],
   "source": [
    "#################################### POS Detection ####################################\n",
    "\n",
    "# category\n",
    "ner_tags = '''noun, verb, adjective, adverb, pronoun, preposition, conjunction, interjection, determiner, cardinal, foreign, number, date, time, ordinal, money, percent, symbol, punctuation, emoticon, hashtag, email, url, mention, phone, ip, cashtag, entity, noun_phrase, verb_phrase, adjective_phrase, adverb_phrase, pronoun_phrase, preposition_phrase, conjunction_phrase, interjection_phrase, determiner_phrase, cardinal_phrase, foreign_phrase, number_phrase, date_phrase, time_phrase, ordinal_phrase, money_phrase, percent_phrase, symbol_phrase, punctuation_phrase, emoticon_phrase, hashtag_phrase, email_phrase, url_phrase, mention_phrase, phone_phrase, ip_phrase, cashtag_phrase, entity_phrase'''\n",
    "\n",
    "# input text\n",
    "user_input = \"I will meet you at airport sharp 12:00 AM.\"\n",
    "\n",
    "# question to be asked\n",
    "question = f'''Given the input text, perform POS detection on it\n",
    "NER Tags are: {ner_tags}\n",
    "{user_input}\n",
    "answer must be in format\n",
    "word: POS\n",
    "'''\n",
    "\n",
    "# generate response\n",
    "response = model.generate_content(question)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Translation:**\n",
    "   - Translating text from one language to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fareed es genio'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################### Machine Translation ####################################\n",
    "\n",
    "# provide list of languages that contain english\n",
    "lang = [\"hindi\",  \"english\", \"spanish\", \"french\", \"german\", \"italian\", \"chinese\", \"japanese\", \"korean\", \"arabic\", \"russian\", \"turkish\", \"portuguese\", \"dutch\", \"greek\", \"polish\", \"romanian\", \"swedish\", \"hungarian\", \"czech\", \"danish\", \"finnish\", \"norwegian\", \"slovak\", \"slovenian\", \"lithuanian\", \"latvian\", \"estonian\", \"bulgarian\", \"serbian\", \"croatian\", \"hebrew\", \"indonesian\", \"vietnamese\", \"thai\", \"hindi\", \"bengali\", \"farsi\", \"malay\", \"tagalog\", \"urdu\", \"hindi\", \"english\", \"spanish\", \"french\", \"german\", \"italian\", \"chinese\", \"japanese\", \"korean\", \"arabic\", \"russian\", \"turkish\", \"portuguese\", \"dutch\", \"greek\", \"polish\", \"romanian\", \"swedish\", \"hungarian\", \"czech\", \"danish\", \"finnish\", \"norwegian\", \"slovak\", \"slovenian\", \"lithuanian\", \"latvian\", \"estonian\", \"bulgarian\", \"serbian\", \"croatian\", \"hebrew\", \"indonesian\", \"vietnamese\"]\n",
    "\n",
    "# input text\n",
    "user_input = \"I will meet you at airport sharp 12:00 AM.\"\n",
    "\n",
    "# question to be asked\n",
    "question = f'''Translate the below input text it into {lang[2]} language:\n",
    "{user_input}\n",
    "'''\n",
    "\n",
    "# generate response\n",
    "response = model.generate_content(question)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Summarization:**\n",
    "   - Generating a concise summary of a longer text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A meeting is scheduled at the airport at midnight.'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################### Text Summarization ####################################\n",
    "\n",
    "# input text\n",
    "user_input = \"I will meet you at airport sharp 12:00 AM.\"\n",
    "\n",
    "# length category\n",
    "summ_category = [\"short\", \"medium\", \"long\"]\n",
    "\n",
    "# question to be asked\n",
    "question = f'''summarize the below input text of {summ_category[1]}  length:\n",
    "{user_input}\n",
    "'''\n",
    "\n",
    "# generate response\n",
    "response = model.generate_content(question)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question Answering:**\n",
    "   - Providing relevant answers to user queries based on a given context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No, it is not possible for an ant to kill a lion. Ants are small insects, typically measuring a few millimeters in length, while lions are large predators that can weigh hundreds of kilograms. Even if an ant could bite a lion, the bite would be too small to cause any significant harm. Additionally, lions have thick fur that would protect them from ant bites. Therefore, it is not possible for an ant to kill a lion.'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################### Question Answering ####################################\n",
    "\n",
    "# input text\n",
    "user_input = \"is it possible that an ant can kill a lion?\"\n",
    "\n",
    "# question to be asked\n",
    "question = f'''answer the following question:\n",
    "{user_input}\n",
    "'''\n",
    "\n",
    "# generate response\n",
    "response = model.generate_content(question)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Generation:**\n",
    "   - Creating human-like text based on given prompts or context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a realm of wonder and delight,\n",
      "Where shadows dance and stars ignite,\n",
      "There lived a cat and a mouse so small,\n",
      "Bound by a friendship beyond all.\n",
      "\n",
      "The cat, with fur as soft as silk,\n",
      "Possessed a heart filled with warmth and ilk,\n",
      "While the mouse, nimble and quick as a bee,\n",
      "Had eyes that sparkled with mirth and glee.\n",
      "\n",
      "They met one day in a moonlit glade,\n",
      "Under the canopy of a willow's shade,\n",
      "The cat, curious, approached with caution,\n",
      "The mouse, brave, showed no hesitation.\n",
      "\n",
      "Through shared laughter and secret whispers,\n",
      "Their bond grew stronger, dispelling the fissures,\n",
      "They chased fireflies in the twilight's embrace,\n",
      "And shared stories till dawn's rosy face.\n",
      "\n",
      "The cat protected the mouse from harm's way,\n",
      "A guardian angel, night and day,\n",
      "The mouse, in turn, brought joy and cheer,\n",
      "Their friendship, a treasure, crystal clear.\n",
      "\n",
      "In a world where differences oft divide,\n",
      "Their unity served as a beacon's guide,\n",
      "A testament to friendship's enduring might,\n",
      "A symbol of love that forever shines bright.\n"
     ]
    }
   ],
   "source": [
    "#################################### Text Generation ####################################\n",
    "\n",
    "# length of gemerated text\n",
    "summ_category = [\"short\", \"medium\", \"long\"]\n",
    "\n",
    "\n",
    "# input text\n",
    "user_input = f'''poem on a friendship between a cat and a mouse'''\n",
    "\n",
    "# question to be asked\n",
    "question = f'''generate a {summ_category[0]} text,\n",
    "{user_input}\n",
    "'''\n",
    "\n",
    "# generate response\n",
    "response = model.generate_content(question)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Semantic Role Labeling (SRL):**\n",
    "   - Identifying the roles of different components in a sentence (e.g., who is doing what to whom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicate: approaching\n",
      "Roles:\n",
      "- Agent: tornado\n",
      "- Theme: city\n"
     ]
    }
   ],
   "source": [
    "#################################### Semantic Role Labeling SRL Implementation ####################################\n",
    "\n",
    "# input text\n",
    "user_input = \"tornado is approaching the city, please take shelter\"\n",
    "\n",
    "# question to be asked\n",
    "question = f'''Given the input text, perform Semantic Role Labeling detection on it\n",
    "{user_input}\n",
    "Output must be\n",
    "Predicate:\n",
    "Roles:\n",
    "-\n",
    "-\n",
    "-\n",
    "'''\n",
    "\n",
    "# generate response\n",
    "response = model.generate_content(question)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intent Recognition:**\n",
    "   - Determining the purpose or goal behind a user's input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent: Safety warning\n"
     ]
    }
   ],
   "source": [
    "#################################### Intent Recognition Implementation ####################################\n",
    "\n",
    "# input text\n",
    "user_input = \"tornado is approaching the city, please take shelter\"\n",
    "\n",
    "# question to be asked\n",
    "question = f'''Given the input text, perform Intent Recognition detection on it\n",
    "{user_input}\n",
    "Output must be\n",
    "Intent:\n",
    "'''\n",
    "\n",
    "# generate response\n",
    "response = model.generate_content(question)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cluster 1': {'Documents': ['animals are running towards the jungle.', 'Are tiger and lion same?'], 'Keywords': ['animals', 'jungle', 'tiger', 'lion']}, 'Cluster 2': {'Documents': ['we will be leaving for office in 10 minutes.'], 'Keywords': ['office', 'minutes']}}\n"
     ]
    }
   ],
   "source": [
    "#################################### Text Clustering Implementation ####################################\n",
    "\n",
    "# input text\n",
    "user_input = '''animals are running towards the jungle. we will be leaving for office in 10 minutes. Are tiger and lion same?'''\n",
    "\n",
    "# question to be asked\n",
    "question = f'''Given the input sentences with full stop defines sentence ends, perform Text Clustering detection on it\n",
    "{user_input}\n",
    "Output must be in this format dictionary format:\n",
    "\n",
    " \"Cluster 1\": dictionary\n",
    "  \"Documents\": list of sentences\n",
    "  \"Keywords\": list of keywords\n",
    " ,\n",
    " \"Cluster 2\": dictionary\n",
    "  \"Documents\": list of sentences\n",
    "  \"Keywords\": list of keywords\n",
    "'''\n",
    "\n",
    "# generate response\n",
    "response = model.generate_content(question)\n",
    "\n",
    "# convert string of dict to dict using ast\n",
    "dict_str = response.text.replace(\"True\", \"True,\")\n",
    "dict_str = dict_str.replace(\"False\", \"False,\")\n",
    "dict_str = dict_str.replace(\"None\", \"None,\")\n",
    "dict_str = ast.literal_eval(dict_str)\n",
    "print(dict_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Core NLP Tasks:**\n",
    "   - Tokenization, Lemmatization, and Stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'cats', 'are', 'running', 'and', 'playing', 'in', 'the', 'gardens', ',', 'while', 'the', 'dogs', 'are', 'barking', 'loudly', 'and', 'chasing', 'their', 'tails']\n"
     ]
    }
   ],
   "source": [
    "#################################### Tokenization Implementation ####################################\n",
    "\n",
    "# input text\n",
    "user_input = '''The cats are running and playing in the gardens, while the dogs are barking loudly and chasing their tails'''\n",
    "\n",
    "# question to be asked\n",
    "question = f'''Given the input sentence perform tokenization on it\n",
    "{user_input}\n",
    "output must be a list of tokens\n",
    "'''\n",
    "\n",
    "# generate response\n",
    "response = model.generate_content(question)\n",
    "\n",
    "# convert string of list to list using ast\n",
    "list_str = response.text.replace(\"True\", \"True,\")\n",
    "list_str = list_str.replace(\"False\", \"False,\")\n",
    "list_str = list_str.replace(\"None\", \"None,\")\n",
    "list_str = ast.literal_eval(list_str)\n",
    "print(list_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cat be run and play in the garden, while the dog be bark loud and chase their tail'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################### Lemmatization Implementation ####################################\n",
    "\n",
    "# input text\n",
    "user_input = '''The cats are running and playing in the gardens, while the dogs are barking loudly and chasing their tails'''\n",
    "\n",
    "# question to be asked\n",
    "question = f'''Given the input sentence perform Lemmatization on it\n",
    "{user_input}\n",
    "output must be that lemmatized sentence\n",
    "'''\n",
    "\n",
    "# generate response\n",
    "response = model.generate_content(question)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat run play garden , dog bark loud chase tail'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################### Stemming Implementation ####################################\n",
    "\n",
    "# input text\n",
    "user_input = '''The cats are running and playing in the gardens, while the dogs are barking loudly and chasing their tails'''\n",
    "\n",
    "# question to be asked\n",
    "question = f'''Given the input sentence perform Stemming on it\n",
    "{user_input}\n",
    "output must be that lemmatized sentence\n",
    "'''\n",
    "\n",
    "# generate response\n",
    "response = model.generate_content(question)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paraphrase Detection:**\n",
    "   - Determining if two sentences convey the same meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "The two sentences have different wording, but they convey the same meaning. They both state that the sun sets in the west every evening.\n"
     ]
    }
   ],
   "source": [
    "#################################### Paraphrasing detection Implementation ####################################\n",
    "\n",
    "# input text\n",
    "user_input = ['''The sun sets in the west every evening.''','''Every evening, the sun goes down in the west.''']\n",
    "\n",
    "# explanation needed?\n",
    "explanation = 'yes'\n",
    "\n",
    "# check explanation is required\n",
    "if explanation == 'yes':\n",
    "    explanation = 'short explanation: '\n",
    "else:\n",
    "    explanation = 'no explanation'\n",
    "\n",
    "# question to be asked\n",
    "question = f'''Given the input text, determine if two sentences are paraphrase of each other\n",
    "sentence1: {user_input[0]}\n",
    "sentence2: {user_input[1]}\n",
    "answer must be yes or no\n",
    "{explanation}\n",
    "'''\n",
    "\n",
    "# generate response\n",
    "response = model.generate_content(question)\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-gemini-bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

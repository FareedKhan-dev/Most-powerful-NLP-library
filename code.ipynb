{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instantiating the GenAI Gemini model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\faree\\Desktop\\gemini_chatbot\\.venv-gemini-bot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "# Your API key goes here\n",
    "genai.configure(api_key=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> ['The', 'cats', 'are', 'running', 'and', 'playing', 'in', 'the', 'gardens', ',', 'while', 'the', 'dogs', 'are', 'barking', 'loudly', 'and', 'chasing', 'their', 'tails']\n"
     ]
    }
   ],
   "source": [
    "from pre_processing import tokenize_text\n",
    "\n",
    "user_input = '''The cats are running and playing in the gardens, while the dogs are barking loudly and chasing their tails'''\n",
    "\n",
    "my_output = tokenize_text(user_input, model)\n",
    "\n",
    "print(type(my_output), my_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat be run and play in the garden, while the dog be bark loud and chase their tail\n"
     ]
    }
   ],
   "source": [
    "from pre_processing import lemmatize_text\n",
    "\n",
    "# Assuming 'your_model' is the instance of your model\n",
    "user_input = '''The cats are running and playing in the gardens, while the dogs are barking loudly and chasing their tails'''\n",
    "lemmatized_sentence = lemmatize_text(user_input, model)\n",
    "print(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cat ar run and play in the garden, whil the dog ar bark loud and chas their tail\n"
     ]
    }
   ],
   "source": [
    "from pre_processing import stem_text\n",
    "\n",
    "user_input = '''The cats are running and playing in the gardens, while the dogs are barking loudly and chasing their tails'''\n",
    "\n",
    "stemmed_sentence = stem_text(user_input, model)\n",
    "\n",
    "print(stemmed_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern Matching Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['123-456-7890', '523-456-7892', 'x123@gmail.com', 'fareed khan']\n"
     ]
    }
   ],
   "source": [
    "from pre_processing import extract_patterns\n",
    "\n",
    "user_input = '''The phone number of fareed khan is 123-456-7890 and 523-456-7892. Please call for assistance and email me at x123@gmail.com'''\n",
    "\n",
    "# You can add more patterns here separated by commas\n",
    "pattern_matching = '''emal, phone number, name'''\n",
    "\n",
    "extracted_patterns = extract_patterns(user_input, pattern_matching, model)\n",
    "\n",
    "print(extracted_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Cleaning Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fareed Khan will arrive at 9:00 AM. He will meet you at the airport. He will be driving a black BMW. His license plate is 123-456-7890.\n"
     ]
    }
   ],
   "source": [
    "from pre_processing import clean_text\n",
    "\n",
    "user_input = '''faree$$@$%d khan will arrive at 9:00 AM. He will@%$ 1meet you at the airport. He will be driving a black BMW. His license plate is 123-456-7890.'''\n",
    "\n",
    "cleaned_text = clean_text(user_input, model)\n",
    "\n",
    "print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTML tags removal Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is bold and italic text.\n"
     ]
    }
   ],
   "source": [
    "from pre_processing import remove_html_tags\n",
    "\n",
    "user_input = '''<p>This is <b>bold</b> and <i>italic</i> text.</p>'''\n",
    "\n",
    "# You can add more tags here separated by commas\n",
    "html_tags = '''<p>, <b>, <i>''' \n",
    "\n",
    "cleaned_text = remove_html_tags(user_input, html_tags, model)\n",
    "\n",
    "print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace text Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like rabbits, but I don't like dogs.\n"
     ]
    }
   ],
   "source": [
    "from pre_processing import replace_text\n",
    "\n",
    "user_input = '''I like cats, but I don't like dogs.'''\n",
    "\n",
    "# You can add more rules here separated by commas\n",
    "replacement_rules = '''all animals to rabbits'''\n",
    "\n",
    "modified_text = replace_text(user_input, replacement_rules, model)\n",
    "\n",
    "print(modified_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Embedding Vectors Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0195884,\n",
       " 0.024218114,\n",
       " -0.029704109,\n",
       " -0.05665759,\n",
       " -0.011961627,\n",
       " -0.026998892,\n",
       " -0.024396203,\n",
       " -0.021466378,\n",
       " 0.021265924,\n",
       " -0.0027763597]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pre_processing import extract_embeddings\n",
    "\n",
    "user_input = [\"cats are running and playing in the gardens\", \"dogs are barking loudly and chasing their tails\"]\n",
    "\n",
    "# extract_embeddings() takes a list of strings as input\n",
    "modified_text = extract_embeddings(user_input)\n",
    "\n",
    "# print first 10 values of embedding vector the first sentence\n",
    "modified_text['embedding'][0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Classification:**\n",
    "   - Sentiment Analysis\n",
    "   - Topic Classification\n",
    "   - Spam Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Category: Negative**\n",
      "\n",
      "**Short Explanation:**\n",
      "\n",
      "The overall sentiment of the text is negative. The author expresses a love for football but then goes on to say that they are feeling very sad and do not want to play football today. This indicates a negative sentiment towards the activity of playing football.\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import analyze_sentiment\n",
    "\n",
    "user_input = \"I love to play football, but today I am feeling very sad. I do not want to play football today.\"\n",
    "\n",
    "# You can add more categories here separated by commas (Default: positive, negative, neutral)\n",
    "category = \"positive, negative, neutral\"\n",
    "\n",
    "sentiment_result = analyze_sentiment(input_text=user_input, category=category, explanation=True, model=model)\n",
    "print(sentiment_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: Story\n",
      "Explanation: The input text is a story about a person who loves to play football but is feeling sad and does not want to play today. The text does not contain any elements of horror or comedy, so the topic is classified as \"story\".\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import classify_topic\n",
    "\n",
    "user_input = \"I love to play football, but today I am feeling very sad. I do not want to play football today.\"\n",
    "\n",
    "# You can add more topics here separated by commas (Default: story, horror, comedy)\n",
    "topics = \"topics are: story, horror, comedy\"\n",
    "\n",
    "topic_result = classify_topic(input_text=user_input, topics=topics, explanation=True, model=model)\n",
    "\n",
    "print(topic_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spam Detection Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n",
      "\n",
      "Explanation: The message contains the promise of a large monetary reward, which is a classic tactic used by spammers to attract attention and entice people to click on the link. The use of the word \"claim\" also indicates the sender's desire to obtain personal information from the recipient, which is another common goal of spammers.\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import detect_spam\n",
    "\n",
    "user_input = \"you have just won $14000, claim this award here at this link.\"\n",
    "\n",
    "# You can add more categories here separated by commas (Default: spam, not spam, unknown)\n",
    "category = 'spam, not_spam, unknown'\n",
    "\n",
    "spam_result = detect_spam(input_text=user_input, category=category, explanation=True, model=model)\n",
    "\n",
    "print(spam_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NER Detection Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airport: facility\n",
      "12:00 AM: time\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import detect_ner\n",
    "\n",
    "user_input = \"I will meet you at the airport sharp 12:00 AM.\"\n",
    "\n",
    "# You can add more categories here separated by commas (Default: erson, location, date, number ... cardinal)\n",
    "ner_tags = 'person, location, date, number, organization, time, money, percent, facility, product, event, language, law, ordinal, misc, quantity, cardinal'\n",
    "\n",
    "ner_result = detect_ner(input_text=user_input, ner_tags=ner_tags, model=model)\n",
    "print(ner_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS Tagging Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: pronoun\n",
      "will: verb\n",
      "meet: verb\n",
      "you: pronoun\n",
      "at: preposition\n",
      "the: determiner\n",
      "airport: noun\n",
      "sharp: adverb\n",
      "12:00: time\n",
      "AM: time\n",
      ".: punctuation\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import detect_pos\n",
    "\n",
    "user_input = \"I will meet you at the airport sharp 12:00 AM.\"\n",
    "\n",
    "# you can add more categories here separated by commas (Default: NOUN, 'noun, verb, ..., cashtag_phrase, entity_phrase')\n",
    "pos_tags = 'noun, verb, adjective, adverb, pronoun, preposition, conjunction, interjection, determiner, cardinal, foreign, number, date, time, ordinal, money, percent, symbol, punctuation, emoticon, hashtag, email, url, mention, phone, ip, cashtag, entity, noun_phrase, verb_phrase, adjective_phrase, adverb_phrase, pronoun_phrase, preposition_phrase, conjunction_phrase, interjection_phrase, determiner_phrase, cardinal_phrase, foreign_phrase, number_phrase, date_phrase, time_phrase, ordinal_phrase, money_phrase, percent_phrase, symbol_phrase, punctuation_phrase, emoticon_phrase, hashtag_phrase, email_phrase, url_phrase, mention_phrase, phone_phrase, ip_phrase, cashtag_phrase, entity_phrase'\n",
    "\n",
    "pos_result = detect_pos(input_text=user_input, pos_tags=pos_tags, model=model)\n",
    "\n",
    "print(pos_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Translation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Te encontraré en el aeropuerto en punto de las 12:00 AM.\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import translate_text\n",
    "\n",
    "user_input = \"I will meet you at the airport sharp 12:00 AM.\"\n",
    "\n",
    "source_language = \"english\"\n",
    "\n",
    "target_language = \"spanish\"\n",
    "\n",
    "translation_result = translate_text(user_input, source_language, target_language, model)\n",
    "\n",
    "print(translation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Summarization Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are requested to meet at the airport promptly at midnight.\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import summarize_text\n",
    "\n",
    "user_input = \"I will meet you at the airport sharp 12:00 AM.\"\n",
    "\n",
    "summary_length = \"medium\" # short, medium, long\n",
    "\n",
    "summary_result = summarize_text(user_input, summary_length, model)\n",
    "\n",
    "print(summary_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question Answering Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, it is not possible for an ant to kill a lion.\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import answer_question\n",
    "\n",
    "question_text = \"Is it possible that an ant can kill a lion?\"\n",
    "\n",
    "answer_result = answer_question(question_text, model=model)\n",
    "\n",
    "print(answer_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Generation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a tale of unique bond, so true,\n",
      "A cat and a mouse, friendship grew.\n",
      "Amidst the world of chase and prey,\n",
      "Their hearts entwined in a different way.\n",
      "\n",
      "The cat, playful and sleek and sly,\n",
      "The mouse, nimble and bright of eye,\n",
      "Met one day in the corner old,\n",
      "Where stories and secrets were untold.\n",
      "\n",
      "They talked and laughed, they shared their dreams,\n",
      "Of chasing stars and moonbeams.\n",
      "No longer bound by predator or prey,\n",
      "They found a bond that would never sway.\n",
      "\n",
      "Together they'd explore the night,\n",
      "Underneath the silver moonlight.\n",
      "A dance of shadows, soft and sweet,\n",
      "Where differences were obsolete.\n",
      "\n",
      "They'd share their meals, they'd share their home,\n",
      "A friendship that would forever roam.\n",
      "In a world of chaos, a gentle grace,\n",
      "A cat and a mouse, in harmony's embrace.\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import generate_text\n",
    "\n",
    "prompt_text = \"poem on a friendship between a cat and a mouse\"\n",
    "\n",
    "generation_length = \"short\"\n",
    "\n",
    "generated_text = generate_text(prompt_text, generation_length, model)\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Role Labeling (SRL) Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicate: approach\n",
      "Roles:\n",
      "- Agent: tornado\n",
      "- Theme: city\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import perform_srl\n",
    "\n",
    "user_input = \"tornado is approaching the city, please take shelter\"\n",
    "\n",
    "srl_result = perform_srl(user_input, model)\n",
    "\n",
    "print(srl_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intent Recognition Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent: Emergency alert\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import recognize_intent\n",
    "\n",
    "user_input = \"tornado is approaching the city, please take shelter\"\n",
    "\n",
    "intent_result = recognize_intent(user_input, model)\n",
    "\n",
    "print(intent_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paraphrasing Detection Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "Both sentences express the same idea that the sun sets in the west every evening. They use different words to convey the same meaning, such as \"sets\" and \"goes down\" for the verb and \"every evening\" for the temporal modifier.\n"
     ]
    }
   ],
   "source": [
    "from core_nlp import paraphrasing_detection\n",
    "\n",
    "user_input = ['''The sun sets in the west every evening.''','''Every evening, the sun goes down in the west.''']\n",
    "\n",
    "intent_result = paraphrasing_detection(input_text=user_input, explanation=True, model=model)\n",
    "\n",
    "print(intent_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-gemini-bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
